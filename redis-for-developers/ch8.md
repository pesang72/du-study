# 복제


## 레디스에서의 복제 구조
- 마스터 노드에서 발생한 쓰기 작업은 연결된 모든 리플리카 노드에 전파된다.
- 리플리카는 읽기 전용으로 활용하거나 장애 복구 시 마스터로 승격할 수 있다.
- 리플리카는 read only로 부하분산을 통해 마스터 트래픽을 분산시킬 수 있다.

### 복제 구조 구성하기
    replicaof <master-ip> <master-port>
- 레디스에서는 마스터에 여러개의 복제본이 연결되 룻 있고, 복제본 노드에 새로운 복제본을 추가하는것도 가능 (하는경우가 뭘까..?)


## 복제 메커니즘 (버전 7 이전)
1) REPLICAOF 명령어로 복제연결을 시도
2) 마스터 노트에서는 fork로 자식 프로세스를 생성, RDB 스냅샷을 생성한다.
3)  (2)번 과정동안, 마스터 노드에서 수행된 모든 데이터셋 변경 작업은 레디스 프로토콜 형태로 마스터의 복제 버퍼에 저장
4) RDB파일이 생성되면 파일은 복제본 노드로 복사
5) 복제본에 저장됐던 모든 내용을 모두 삭제한 뒤 RDB파일을 이용해 데이터를 로딩
6) 복제 과정동안 버터링됐던 복제 버퍼의 데이터를 복제본으로 전달해 수행

### 📌 실제로 복제가 느려지는 주요 원인
| 구간            | 설명 |
|------------------|------|
| RDB 생성 지연     | 마스터의 메모리가 클수록 fork + RDB 생성 시간이 증가함 |
| 리플리카 데이터 삭제 | 전체 삭제 후 재로딩이기 때문에 GC, 메모리 관리 비용 큼 |
| 복제 버퍼 처리량 증가 | 동기화 시간 중 write가 집중되면, 복제 후 적용 지연 초래 |


## 복제 메커니즘 (버전 7 이후, Diskless + PSYNC2 기준)
1) 리플리카 노드가 `REPLICAOF` 명령 또는 `replicaof` 설정을 통해 마스터에 연결 요청  
2) 마스터는 리플리카와 **PSYNC2 협상**을 수행해 부분 복제가 가능한지 확인
    - PSYNC2는 run ID와 replication offset을 기준으로 부분 복제 가능 여부를 판단함
    - 실패 시 **전체 복제(full resync)** 진행  
3) 전체 복제일 경우, 마스터는 **fork를 사용해 자식 프로세스를 생성**
    - 자식 프로세스는 **디스크에 저장하지 않고**, 메모리에서 직접 RDB 데이터를 **소켓으로 전송**함
    - 이를 **Diskless Replication**이라 부른다  
4) 리플리카는 받은 RDB 데이터를 **그대로 메모리에 로드**함
    - 이때 기존 데이터는 삭제되고 새로운 상태로 교체됨
5) 복제 도중 마스터에 수행된 쓰기 명령은 **복제 버퍼에 임시 저장**됨
    - 마스터는 **RDB 전송 완료 직후**, 복제 버퍼에 있는 명령어 스트림도 함께 리플리카에 전송  
6) 리플리카는 명령어 스트림을 실행하여 **마스터와 완전히 동기화된 상태로 전환**


## 복제 메커니즘 PSYNC2 기반의 부분 복제 (Partial Resync)

- 리플리카가 재접속할 때, 마스터의 **replication backlog**를 참조하여 끊긴 이후의 명령만 전송함
- 마스터와 리플리카가 다음 조건을 만족하면 부분 복제가 수행됨:
    - 동일한 `runid`
    - 리플리카가 보유한 `replication offset`이 backlog 내에 포함됨

- 실패할 경우에는 다시 전체 복제로 전환됨 (fallback)
